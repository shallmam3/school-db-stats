import streamlit as st
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import pandas as pd
import time

# --- æ ¸å¿ƒé€»è¾‘ ---

def get_dynamic_page_content(url):
    """
    ä½¿ç”¨ Playwright åŠ è½½åŠ¨æ€ç½‘é¡µï¼ˆé’ˆå¯¹è¶…æ˜Ÿ/AJAXé¡µé¢ï¼‰
    """
    with sync_playwright() as p:
        # å¯åŠ¨ä¸€ä¸ªæµè§ˆå™¨ï¼ˆheadless=True è¡¨ç¤ºä¸æ˜¾ç¤ºç•Œé¢ï¼Œé€Ÿåº¦æ›´å¿«ï¼‰
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        try:
            print(f"æ­£åœ¨åŠ è½½é¡µé¢: {url}")
            page.goto(url, timeout=30000) # 30ç§’è¶…æ—¶
            
            # å…³é”®ç‚¹ï¼šç­‰å¾…é¡µé¢ä¸Šçš„ç‰¹å®šå…ƒç´ åŠ è½½å‡ºæ¥
            # æˆ‘ä»¬ç­‰å¾…é¡µé¢ä¸Šå‡ºç°çœ‹èµ·æ¥åƒé“¾æ¥æˆ–åˆ—è¡¨çš„ä¸œè¥¿
            # å¦‚æœä½ çŸ¥é“å…·ä½“çš„ CSS é€‰æ‹©å™¨æœ€å¥½ï¼Œä¸çŸ¥é“çš„è¯ç­‰å¾…ç½‘ç»œç©ºé—²
            page.wait_for_load_state("networkidle") 
            
            # ä¸ºäº†ä¿é™©ï¼Œå¤šç­‰ 2 ç§’è®© JS æ¸²æŸ“å®Œ
            time.sleep(2)
            
            # è·å–æ¸²æŸ“åçš„å®Œæ•´ HTML
            content = page.content()
            return content
            
        except Exception as e:
            st.error(f"Playwright åŠ è½½å¤±è´¥: {e}")
            return None
        finally:
            browser.close()

def is_chinese(string):
    for char in string:
        if '\u4e00' <= char <= '\u9fa5':
            return True
    return False

def analyze_html(html_content):
    """è§£æ HTML å†…å®¹"""
    if not html_content:
        return [], []
        
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # æ¸…ç†å¹²æ‰°é¡¹
    for tag in soup(['header', 'footer', 'nav', 'script', 'style', 'noscript']):
        tag.decompose()
    
    links = soup.find_all('a')
    db_list = []
    
    for link in links:
        text = link.get_text(strip=True)
        # ç¨å¾®æ”¾å®½è¿‡æ»¤æ¡ä»¶
        if 2 < len(text) < 50: 
            db_list.append(text)
    
    db_list = list(set(db_list))
    
    cn_dbs = [db for db in db_list if is_chinese(db)]
    other_dbs = [db for db in db_list if not is_chinese(db)]
            
    return cn_dbs, other_dbs

# --- UI ç•Œé¢ ---

st.set_page_config(page_title="åŠ¨æ€ç½‘é¡µæ•°æ®åº“æŠ“å–", page_icon="ğŸ•µï¸")

st.title("ğŸ•µï¸ è¶…æ˜Ÿ/åŠ¨æ€ç½‘é¡µæŠ“å–åŠ©æ‰‹")
st.markdown("ä¸“é—¨è§£å†³â€œæµè§ˆå™¨èƒ½çœ‹åˆ°ï¼Œç¨‹åºæœä¸åˆ°â€çš„é—®é¢˜ã€‚")

target_url = st.text_input("è¯·è¾“å…¥ç½‘å€ï¼š", value="http://wisdom.chaoxing.com/newwisdom/doordatabase/database.html?pageId=48038&wfwfid=1803&sw=")

if st.button("å¼€å§‹å¼ºåŠ›æŠ“å–"):
    if not target_url:
        st.warning("è¯·å…ˆè¾“å…¥ç½‘å€")
    else:
        with st.status("ğŸš€ æ­£åœ¨å¯åŠ¨ä»¿çœŸæµè§ˆå™¨...", expanded=True) as status:
            
            # 1. è·å–åŠ¨æ€å†…å®¹
            html_content = get_dynamic_page_content(target_url)
            
            if html_content:
                status.write("âœ… é¡µé¢åŠ è½½æˆåŠŸï¼æ­£åœ¨è§£ææ•°æ®...")
                
                # 2. è§£æ
                cn_list, en_list = analyze_html(html_content)
                
                status.update(label="åˆ†æå®Œæˆï¼", state="complete", expanded=False)
                
                # 3. å±•ç¤ºç»“æœ
                st.divider()
                st.success(f"ğŸ“Š æŠ“å–ç»“æœç»Ÿè®¡")
                
                col1, col2, col3 = st.columns(3)
                col1.metric("ä¸­æ–‡æ•°æ®åº“", f"{len(cn_list)}")
                col2.metric("å¤–æ–‡/å…¶ä»–", f"{len(en_list)}")
                col3.metric("æ€»è®¡", f"{len(cn_list) + len(en_list)}")
                
                tab1, tab2 = st.tabs(["ğŸ“ ä¸­æ–‡åº“æ¸…å•", "ğŸŒ å¤–æ–‡åº“æ¸…å•"])
                with tab1:
                    st.dataframe(pd.DataFrame(cn_list, columns=["åç§°"]), use_container_width=True)
                with tab2:
                    st.dataframe(pd.DataFrame(en_list, columns=["åç§°"]), use_container_width=True)
            else:
                status.update(label="æŠ“å–å¤±è´¥", state="error")
                st.error("æœªèƒ½è·å–é¡µé¢å†…å®¹ï¼Œå¯èƒ½æ˜¯å› ä¸ºç½‘é¡µæœ‰åçˆ¬è™«éªŒè¯æˆ–åŠ è½½è¶…æ—¶ã€‚")